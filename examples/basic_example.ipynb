{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Sinergym uses the standard OpenAI gym API. Lets see how to create a basic loop.\n",
    "\n",
    "First we need to include sinergym and create an environment, in our case using 'Eplus-demo-v1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import sinergym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('Eplus-demo-v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "At first glance may appear that sinergym is only imported but never used, but by importing Sinergym all its [Environments](https://ugr-sail.github.io/sinergym/compilation/html/pages/environments.html)\n",
    "are defined to be used, in this case 'Eplus-demo-v1' with all the information contained in the idf file and the config file.\n",
    "\n",
    "After this simple definition we are ready to loop the episodes, for this simple example we are going to consider only 1 episode. In summary the code we need is something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-17 05:43:41,335] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-05-17 05:43:41,519] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /root/my-project/examples/Eplus-env-demo-v1-res8/Eplus-env-sub_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -0.18054534463652905 {'timestep': 1, 'time_elapsed': 900, 'year': 1991, 'month': 1, 'day': 1, 'hour': 0, 'action': [21, 21], 'reward': -0.18054534463652905, 'reward_energy': -1.8054534463652903, 'reward_comfort': -0.0, 'total_energy': 18054.5344636529, 'abs_comfort': 0.0, 'temperatures': [20.99998833869494, 20.81866975215882, 20.9999880037787, 20.71504075275832, 20.99998305378782]}\n",
      "Reward:  -5763.117736881167 {'timestep': 2976, 'time_elapsed': 2678400, 'year': 1991, 'month': 2, 'day': 1, 'hour': 0, 'action': [22, 23], 'reward': -0.2266049065564041, 'reward_energy': -2.266049065564041, 'reward_comfort': -0.0, 'total_energy': 22660.49065564041, 'abs_comfort': 0.0, 'temperatures': [21.64848453584105, 20.27223518090898, 21.59761757334702, 20.19741394829678, 20.66473502531415]}\n",
      "Reward:  -12028.195440598773 {'timestep': 5664, 'time_elapsed': 5097600, 'year': 1991, 'month': 3, 'day': 1, 'hour': 0, 'action': [20, 25], 'reward': -0.32230673238890206, 'reward_energy': -0.974010773646954, 'reward_comfort': -0.2498951722491185, 'total_energy': 9740.10773646954, 'abs_comfort': 0.2498951722491185, 'temperatures': [19.95299436499253, 19.95594756488292, 19.95386050704232, 19.95604673900063, 19.93125565183248]}\n",
      "Reward:  -16077.938140373422 {'timestep': 8640, 'time_elapsed': 7776000, 'year': 1991, 'month': 4, 'day': 1, 'hour': 0, 'action': [20, 25], 'reward': -0.004208166210919131, 'reward_energy': -0.04208166210919131, 'reward_comfort': -0.0, 'total_energy': 420.8166210919131, 'abs_comfort': 0.0, 'temperatures': [20.30739271616658, 20.26126043949925, 20.30774210552199, 20.2616628960033, 21.08455457553629]}\n",
      "Reward:  -19136.560621507826 {'timestep': 11520, 'time_elapsed': 10368000, 'year': 1991, 'month': 5, 'day': 1, 'hour': 0, 'action': [20, 25], 'reward': -0.0015248689534142462, 'reward_energy': -0.01524868953414246, 'reward_comfort': -0.0, 'total_energy': 152.4868953414246, 'abs_comfort': 0.0, 'temperatures': [20.49885407168512, 20.54913608569358, 20.49361308857199, 20.55579984892159, 20.77621502267291]}\n",
      "Reward:  -22051.56675894406 {'timestep': 14496, 'time_elapsed': 13046400, 'year': 1991, 'month': 6, 'day': 1, 'hour': 0, 'action': [21, 21], 'reward': -9.085084776077753, 'reward_energy': -0.4539995564515574, 'reward_comfort': -10.044094244925109, 'total_energy': 4539.995564515573, 'abs_comfort': 10.044094244925109, 'temperatures': [20.9944355857318, 20.98540912693748, 20.99392011533245, 20.98586455578913, 20.99627637128403]}\n",
      "Reward:  -42133.83473137345 {'timestep': 17376, 'time_elapsed': 15638400, 'year': 1991, 'month': 7, 'day': 1, 'hour': 0, 'action': [21, 24], 'reward': -6.412616590603127, 'reward_energy': -0.01757866565714596, 'reward_comfort': -7.123176360041569, 'total_energy': 175.7866565714596, 'abs_comfort': 7.123176360041569, 'temperatures': [21.58097787921579, 21.43402931191957, 21.57858760220817, 21.43389599054563, 21.84933285606927]}\n",
      "Reward:  -63666.394882829336 {'timestep': 20352, 'time_elapsed': 18316800, 'year': 1991, 'month': 8, 'day': 1, 'hour': 0, 'action': [21, 24], 'reward': -9.603657393911822, 'reward_energy': -1.4689455465038552, 'reward_comfort': -10.50751426584604, 'total_energy': 14689.45546503855, 'abs_comfort': 10.50751426584604, 'temperatures': [20.95982183818783, 20.80591717576155, 20.95968785239063, 20.78455339206225, 20.9825054757517]}\n",
      "Reward:  -85529.63178402871 {'timestep': 23328, 'time_elapsed': 20995200, 'year': 1991, 'month': 9, 'day': 1, 'hour': 0, 'action': [22, 23], 'reward': -4.893941286854336, 'reward_energy': -0.7113237903699342, 'reward_comfort': -5.358676564241492, 'total_energy': 7113.237903699342, 'abs_comfort': 5.358676564241492, 'temperatures': [22.03136603241333, 21.89453994176315, 22.03245366054669, 21.88550764999431, 21.79745615104103]}\n",
      "Reward:  -105629.21913901456 {'timestep': 26208, 'time_elapsed': 23587200, 'year': 1991, 'month': 10, 'day': 1, 'hour': 0, 'action': [21, 21], 'reward': -0.05059837280081957, 'reward_energy': -0.5059837280081957, 'reward_comfort': -0.0, 'total_energy': 5059.837280081957, 'abs_comfort': 0.0, 'temperatures': [20.98939110229131, 20.99008757415062, 20.98827154279589, 20.98976252316385, 20.99501848222507]}\n",
      "Reward:  -109327.8895340673 {'timestep': 29184, 'time_elapsed': 26265600, 'year': 1991, 'month': 11, 'day': 1, 'hour': 0, 'action': [16, 29], 'reward': -0.0015248689534142462, 'reward_energy': -0.01524868953414246, 'reward_comfort': -0.0, 'total_energy': 152.4868953414246, 'abs_comfort': 0.0, 'temperatures': [20.46816605238585, 20.52386468325633, 20.4761546205512, 20.52088611850332, 20.75445394627289]}\n",
      "Reward:  -112714.81661346061 {'timestep': 32064, 'time_elapsed': 28857600, 'year': 1991, 'month': 12, 'day': 1, 'hour': 0, 'action': [15, 30], 'reward': -1.301871924753015, 'reward_energy': -0.015562483820049933, 'reward_comfort': -1.4447951959677887, 'total_energy': 155.6248382004993, 'abs_comfort': 1.4447951959677887, 'temperatures': [19.55621362455642, 19.70009878045287, 19.59940336385097, 19.69948903517195, 20.35368521961327]}\n",
      "Reward:  -118759.65599010859 {'timestep': 35040, 'time_elapsed': 31536000, 'year': 1992, 'month': 1, 'day': 1, 'hour': 0, 'action': [17, 28], 'reward': -7.473893254447767, 'reward_energy': -0.5016904554313611, 'reward_comfort': -8.248582454338479, 'total_energy': 5016.904554313612, 'abs_comfort': 8.248582454338479, 'temperatures': [18.23388230342863, 17.97276165786988, 18.23968774614396, 17.95695403253673, 19.34813180568232]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    observations = []\n",
    "    terminated = False\n",
    "    current_month = 0\n",
    "    while not terminated:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(a)\n",
    "#         print('Obs: ', obs)\n",
    "        rewards.append(reward)\n",
    "        observations.append(obs)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', sum(rewards), info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Now we can see the final rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward:  -3.389259588758715 Cumulative reward:  -118759.65599010859\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [list of environments](https://github.com/ugr-sail/sinergym/blob/main/sinergym/__init__.py) that we have registered in Sinergym is extensive and we use buildings changing particularities. For example, continuous action space or discrete, noise over weather, runperiod, timesteps, reward function, etc. We will see it in the following notebooks.****"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['year',\n",
       " 'month',\n",
       " 'day',\n",
       " 'hour',\n",
       " 'Site Outdoor Air Drybulb Temperature(Environment)',\n",
       " 'Site Outdoor Air Relative Humidity(Environment)',\n",
       " 'Site Wind Speed(Environment)',\n",
       " 'Site Wind Direction(Environment)',\n",
       " 'Site Diffuse Solar Radiation Rate per Area(Environment)',\n",
       " 'Site Direct Solar Radiation Rate per Area(Environment)',\n",
       " 'Zone Thermostat Heating Setpoint Temperature(SPACE1-1)',\n",
       " 'Zone Thermostat Cooling Setpoint Temperature(SPACE1-1)',\n",
       " 'Zone Air Temperature(SPACE1-1)',\n",
       " 'Zone Air Temperature(SPACE2-1)',\n",
       " 'Zone Air Temperature(SPACE3-1)',\n",
       " 'Zone Air Temperature(SPACE4-1)',\n",
       " 'Zone Air Temperature(SPACE5-1)',\n",
       " 'Zone Thermal Comfort Mean Radiant Temperature(SPACE1-1 PEOPLE 1)',\n",
       " 'Zone Air Relative Humidity(SPACE1-1)',\n",
       " 'Zone Thermal Comfort Clothing Value(SPACE1-1 PEOPLE 1)',\n",
       " 'Zone Thermal Comfort Fanger Model PPD(SPACE1-1 PEOPLE 1)',\n",
       " 'Zone People Occupant Count(SPACE1-1)',\n",
       " 'People Air Temperature(SPACE1-1 PEOPLE 1)',\n",
       " 'Facility Total HVAC Electricity Demand Rate(Whole Building)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.variables['observation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9910000e+03, 1.0000000e+00, 1.0000000e+00, 0.0000000e+00,\n",
       "       1.8000000e+00, 9.5250000e+01, 4.0999999e+00, 2.6500000e+02,\n",
       "       0.0000000e+00, 0.0000000e+00, 2.1000000e+01, 2.1000000e+01,\n",
       "       2.0999989e+01, 2.0818670e+01, 2.0999989e+01, 2.0715040e+01,\n",
       "       2.0999983e+01, 1.9362980e+01, 3.9579979e+01, 7.5000000e-01,\n",
       "       2.9739861e+01, 0.0000000e+00, 2.0999989e+01, 1.8054535e+04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "And as always don't forget to close the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "import sinergym\n",
    "from sinergym.utils.rewards import LinearReward, BaseReward\n",
    "from sinergym.utils import env_checker\n",
    "from datetime import datetime\n",
    "from math import exp\n",
    "from typing import Any, Dict, List, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For checking custom env\n",
    "# env_checker.check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomReward(BaseReward):\n",
    "    def __init__(\n",
    "        self,\n",
    "        temperature_variable: Union[str, list],\n",
    "        occupancy_variable: Union[str, list],\n",
    "        energy_variable: str,\n",
    "        range_comfort_winter: Tuple[int, int],\n",
    "        range_comfort_summer: Tuple[int, int],\n",
    "        summer_start: Tuple[int, int] = (6, 1),\n",
    "        summer_final: Tuple[int, int] = (9, 30),\n",
    "        energy_weight: float = 0.5,\n",
    "        lambda_energy: float = 1e-4,\n",
    "        lambda_temperature: float = 1.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Linear reward function.\n",
    "\n",
    "        It considers the energy consumption and the absolute difference to temperature comfort.\n",
    "\n",
    "        .. math::\n",
    "            R = - W * lambda_E * power - (1 - W) * lambda_T * (max(T - T_{low}, 0) + max(T_{up} - T, 0))\n",
    "\n",
    "        Args:\n",
    "            temperature_variable (Union[str, list]): Name(s) of the temperature variable(s).\n",
    "            occupancy_variable (Union[str, list]): Name(s) of the occupancy variable(s).\n",
    "            energy_variable (str): Name of the energy/power variable.\n",
    "            range_comfort_winter (Tuple[int,int]): Temperature comfort range for cold season. Depends on environment you are using.\n",
    "            range_comfort_summer (Tuple[int,int]): Temperature comfort range for hot season. Depends on environment you are using.\n",
    "            summer_start (Tuple[int,int]): Summer session tuple with month and day start. Defaults to (6,1).\n",
    "            summer_final (Tuple[int,int]): Summer session tuple with month and day end. defaults to (9,30).\n",
    "            energy_weight (float, optional): Weight given to the energy term. Defaults to 0.5.\n",
    "            lambda_energy (float, optional): Constant for removing dimensions from power(1/W). Defaults to 1e-4.\n",
    "            lambda_temperature (float, optional): Constant for removing dimensions from temperature(1/C). Defaults to 1.0.\n",
    "        \"\"\"\n",
    "\n",
    "        super(CustomReward, self).__init__()\n",
    "        \n",
    "        # Check that occupancy_variable is of same type [str, list] as temperature_variable. \n",
    "        # If both are lists, check that they have same length.\n",
    "        if (type(temperature_variable) == type(occupancy_variable)):\n",
    "            if (type(temperature_variable) == list and len(temperature_variable) != len(occupancy_variable)):\n",
    "                raise Exception(\"temperature_variable should have the same length as occupancy_variable\")\n",
    "        else: \n",
    "            raise Exception(\"temperature_variable must be of same type as occupancy_variable\")\n",
    "\n",
    "        # Name of the variables\n",
    "        self.temp_name = temperature_variable\n",
    "        self.occ_name = occupancy_variable\n",
    "        self.energy_name = energy_variable\n",
    "\n",
    "        # Reward parameters\n",
    "        self.range_comfort_winter = range_comfort_winter\n",
    "        self.range_comfort_summer = range_comfort_summer\n",
    "        self.W_energy = energy_weight\n",
    "        self.lambda_energy = lambda_energy\n",
    "        self.lambda_temp = lambda_temperature\n",
    "\n",
    "        # Summer period\n",
    "        self.summer_start = summer_start  # (month,day)\n",
    "        self.summer_final = summer_final  # (month,day)\n",
    "\n",
    "    def __call__(self, obs_dict: Dict[str, Any]\n",
    "                 ) -> Tuple[float, Dict[str, Any]]:\n",
    "        \"\"\"Calculate the reward function.\n",
    "\n",
    "        Args:\n",
    "            obs_dict (Dict[str, Any]): Dict with observation variable name (key) and observation variable value (value)\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, Dict[str, Any]]: Reward value and dictionary with their individual components.\n",
    "        \"\"\"\n",
    "\n",
    "        # Energy term\n",
    "        reward_energy = - self.lambda_energy * obs_dict[self.energy_name]\n",
    "\n",
    "        # Comfort\n",
    "        comfort, temps = self._get_comfort(obs_dict)\n",
    "        reward_comfort = - self.lambda_temp * comfort\n",
    "\n",
    "        # Weighted sum of both terms\n",
    "        reward = self.W_energy * reward_energy + \\\n",
    "            (1.0 - self.W_energy) * reward_comfort\n",
    "\n",
    "        reward_terms = {\n",
    "            'reward_energy': reward_energy,\n",
    "            'reward_comfort': reward_comfort,\n",
    "            'total_energy': obs_dict[self.energy_name],\n",
    "            'abs_comfort': comfort,\n",
    "            'temperatures': temps\n",
    "        }\n",
    "\n",
    "        return reward, reward_terms\n",
    "\n",
    "    def _get_comfort(self,\n",
    "                     obs_dict: Dict[str,\n",
    "                                    Any]) -> Tuple[float,\n",
    "                                                   List[float]]:\n",
    "        \"\"\"Calculate the comfort term of the reward.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[float, List[float]]: comfort penalty and List with temperatures used.\n",
    "        \"\"\"\n",
    "\n",
    "        month = obs_dict['month']\n",
    "        day = obs_dict['day']\n",
    "        year = obs_dict['year']\n",
    "        current_dt = datetime(int(year), int(month), int(day))\n",
    "\n",
    "        # Periods\n",
    "        summer_start_date = datetime(\n",
    "            int(year),\n",
    "            self.summer_start[0],\n",
    "            self.summer_start[1])\n",
    "        summer_final_date = datetime(\n",
    "            int(year),\n",
    "            self.summer_final[0],\n",
    "            self.summer_final[1])\n",
    "\n",
    "        if current_dt >= summer_start_date and current_dt <= summer_final_date:\n",
    "            temp_range = self.range_comfort_summer\n",
    "        else:\n",
    "            temp_range = self.range_comfort_winter\n",
    "\n",
    "        temps = [v for k, v in obs_dict.items() if k in self.temp_name]\n",
    "        occs = [v for k, v in obs_dict.items() if k in self.occ_name]\n",
    "        comfort = 0.0\n",
    "        for T in temps:\n",
    "            if T < temp_range[0] or T > temp_range[1]:\n",
    "                comfort += min(abs(temp_range[0] - T), abs(T - temp_range[1]))\n",
    "\n",
    "        return comfort, temps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-17 06:42:07,068] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf ExternalInterface object if it is not present...\n",
      "[2023-05-17 06:42:07,070] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf Site:Location and SizingPeriod:DesignDay(s) to weather and ddy file...\n",
      "[2023-05-17 06:42:07,072] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Updating idf OutPut:Variable and variables XML tree model for BVCTB connection.\n",
      "[2023-05-17 06:42:07,074] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up extra configuration in building model if exists...\n",
      "[2023-05-17 06:42:07,075] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Setting up action definition in building model if exists...\n"
     ]
    }
   ],
   "source": [
    "OBSERVATION_VARIABLES=[\n",
    "        'Site Outdoor Air Drybulb Temperature(Environment)',\n",
    "        'Site Outdoor Air Relative Humidity(Environment)',\n",
    "        'Site Wind Speed(Environment)',\n",
    "        'Site Wind Direction(Environment)',\n",
    "        'Site Diffuse Solar Radiation Rate per Area(Environment)',\n",
    "        'Site Direct Solar Radiation Rate per Area(Environment)',\n",
    "        'Zone Thermostat Heating Setpoint Temperature(SPACE1-1)',\n",
    "        'Zone Thermostat Cooling Setpoint Temperature(SPACE1-1)',\n",
    "        'Zone Air Temperature(SPACE1-1)',\n",
    "        'Zone Air Temperature(SPACE2-1)',\n",
    "        'Zone Air Temperature(SPACE3-1)',\n",
    "        'Zone Air Temperature(SPACE4-1)',\n",
    "        'Zone Air Temperature(SPACE5-1)',\n",
    "        'Zone Thermal Comfort Mean Radiant Temperature(SPACE1-1 PEOPLE 1)',\n",
    "        'Zone Air Relative Humidity(SPACE1-1)',\n",
    "        'Zone Thermal Comfort Clothing Value(SPACE1-1 PEOPLE 1)',\n",
    "        'Zone Thermal Comfort Fanger Model PPD(SPACE1-1 PEOPLE 1)',\n",
    "        'Zone People Occupant Count(SPACE1-1)',\n",
    "        'People Air Temperature(SPACE1-1 PEOPLE 1)',\n",
    "        'Facility Total HVAC Electricity Demand Rate(Whole Building)'\n",
    "    ]\n",
    "\n",
    "env = gym.make(\n",
    "    'Eplus-demo-v1', \n",
    "    observation_space= gym.spaces.Box(\n",
    "        low=-5e6,\n",
    "        high=5e6,\n",
    "        shape=(len(OBSERVATION_VARIABLES) + 4,),\n",
    "        dtype=np.float32\n",
    "    ),\n",
    "    observation_variables=OBSERVATION_VARIABLES,\n",
    "    reward=CustomReward, \n",
    "    reward_kwargs={\n",
    "        'temperature_variable': [\n",
    "            'Zone Air Temperature(SPACE1-1)',\n",
    "            'Zone Air Temperature(SPACE2-1)',\n",
    "            'Zone Air Temperature(SPACE3-1)',\n",
    "            'Zone Air Temperature(SPACE4-1)',\n",
    "            'Zone Air Temperature(SPACE5-1)',\n",
    "        ],\n",
    "        'occupancy_variable': [\n",
    "            'Zone People Occupant Count(SPACE1-1)',\n",
    "            'Zone People Occupant Count(SPACE2-1)',\n",
    "            'Zone People Occupant Count(SPACE3-1)',\n",
    "            'Zone People Occupant Count(SPACE4-1)',\n",
    "            'Zone People Occupant Count(SPACE5-1)',\n",
    "        ],\n",
    "        'energy_variable': 'Facility Total HVAC Electricity Demand Rate(Whole Building)',\n",
    "        'range_comfort_winter': (20.0, 23.5),\n",
    "        'range_comfort_summer': (23.0, 26.0),\n",
    "        'energy_weight': 0.1\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-17 06:42:11,220] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:Creating new EnergyPlus simulation episode...\n",
      "[2023-05-17 06:42:11,404] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus working directory is in /root/my-project/examples/Eplus-env-demo-v1-res13/Eplus-env-sub_run1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/opyplus/weather_data/weather_data.py:493: FutureWarning: the 'line_terminator'' keyword is deprecated, use 'lineterminator' instead.\n",
      "  epw_content = self._headers_to_epw(use_datetimes=use_datetimes) + df.to_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reward:  -3.349656611852669 {'timestep': 1, 'time_elapsed': 900, 'year': 1991, 'month': 1, 'day': 1, 'hour': 0, 'action': [18, 27], 'reward': -3.349656611852669, 'reward_energy': -0.3780170717786078, 'reward_comfort': -3.679838782972009, 'total_energy': 3780.170717786078, 'abs_comfort': 3.679838782972009, 'temperatures': [19.23928542997237, 18.94104676407819, 19.25996050906064, 18.87986851391679, 20.09605568964284]}\n",
      "Reward:  -6263.744721629314 {'timestep': 2976, 'time_elapsed': 2678400, 'year': 1991, 'month': 2, 'day': 1, 'hour': 0, 'action': [19, 26], 'reward': -5.034556175562543, 'reward_energy': -1.258423096310944, 'reward_comfort': -5.45412651770161, 'total_energy': 12584.23096310944, 'abs_comfort': 5.45412651770161, 'temperatures': [18.944821747237, 18.80525802437179, 18.9468120809365, 18.79149975135721, 19.05748187839589]}\n",
      "Reward:  -11901.467417660475 {'timestep': 5664, 'time_elapsed': 5097600, 'year': 1991, 'month': 3, 'day': 1, 'hour': 0, 'action': [16, 29], 'reward': -2.5270917998007283, 'reward_energy': -0.04903960893636225, 'reward_comfort': -2.802430932118991, 'total_energy': 490.3960893636225, 'abs_comfort': 2.802430932118991, 'temperatures': [19.31224777757458, 19.39876525440188, 19.30841535472958, 19.40281337570132, 19.77532730547365]}\n",
      "Reward:  -16337.738946264062 {'timestep': 8640, 'time_elapsed': 7776000, 'year': 1991, 'month': 4, 'day': 1, 'hour': 0, 'action': [21, 24], 'reward': -0.043268693896735405, 'reward_energy': -0.43268693896735405, 'reward_comfort': -0.0, 'total_energy': 4326.86938967354, 'abs_comfort': 0.0, 'temperatures': [21.00018924846003, 21.00013957673217, 21.00019391963752, 21.00013428474705, 21.0000299602701]}\n",
      "Reward:  -19309.304929551698 {'timestep': 11520, 'time_elapsed': 10368000, 'year': 1991, 'month': 5, 'day': 1, 'hour': 0, 'action': [21, 24], 'reward': -0.031422242161466066, 'reward_energy': -0.31422242161466063, 'reward_comfort': -0.0, 'total_energy': 3142.224216146606, 'abs_comfort': 0.0, 'temperatures': [21.00223575464706, 21.00269295338835, 21.002072608463, 21.00257436569627, 21.06731836977255]}\n",
      "Reward:  -22334.010626600408 {'timestep': 14496, 'time_elapsed': 13046400, 'year': 1991, 'month': 6, 'day': 1, 'hour': 0, 'action': [16, 29], 'reward': -11.273080207349444, 'reward_energy': -0.025735323752778694, 'reward_comfort': -12.52278519441574, 'total_energy': 257.3532375277869, 'abs_comfort': 12.52278519441574, 'temperatures': [20.55352790864314, 20.28698340381496, 20.48902536274816, 20.34971480215495, 20.79796332822305]}\n",
      "Reward:  -42347.064766302356 {'timestep': 17376, 'time_elapsed': 15638400, 'year': 1991, 'month': 7, 'day': 1, 'hour': 0, 'action': [15, 30], 'reward': -9.56408423569839, 'reward_energy': -0.01757796740476127, 'reward_comfort': -10.624807154397683, 'total_energy': 175.7796740476127, 'abs_comfort': 10.624807154397683, 'temperatures': [20.85975828721108, 20.66742893864528, 20.85292909045916, 20.68214356618254, 21.31293296310426]}\n",
      "Reward:  -63836.212651602844 {'timestep': 20352, 'time_elapsed': 18316800, 'year': 1991, 'month': 8, 'day': 1, 'hour': 0, 'action': [16, 29], 'reward': -17.751273664753324, 'reward_energy': -0.3757698749977336, 'reward_comfort': -19.68188519694839, 'total_energy': 3757.698749977336, 'abs_comfort': 19.68188519694839, 'temperatures': [19.16965893430782, 18.82207022902827, 19.15292316936728, 18.80256169020209, 19.37090078014615]}\n",
      "Reward:  -86074.45208590377 {'timestep': 23328, 'time_elapsed': 20995200, 'year': 1991, 'month': 9, 'day': 1, 'hour': 0, 'action': [15, 30], 'reward': -12.549675501857578, 'reward_energy': -0.02964221825034278, 'reward_comfort': -13.940790311147271, 'total_energy': 296.4221825034278, 'abs_comfort': 13.940790311147271, 'temperatures': [20.2880127046517, 19.9404624016771, 20.28181021621172, 19.90822616452397, 20.64069820178824]}\n",
      "Reward:  -106245.21083465501 {'timestep': 26208, 'time_elapsed': 23587200, 'year': 1991, 'month': 10, 'day': 1, 'hour': 0, 'action': [16, 29], 'reward': -0.0015248689534142462, 'reward_energy': -0.01524868953414246, 'reward_comfort': -0.0, 'total_energy': 152.4868953414246, 'abs_comfort': 0.0, 'temperatures': [20.99497253056464, 21.00396558236955, 20.98285762377213, 21.00015043802414, 21.31280016102912]}\n",
      "Reward:  -110360.21200449787 {'timestep': 29184, 'time_elapsed': 26265600, 'year': 1991, 'month': 11, 'day': 1, 'hour': 0, 'action': [15, 30], 'reward': -0.0015248689534142462, 'reward_energy': -0.01524868953414246, 'reward_comfort': -0.0, 'total_energy': 152.4868953414246, 'abs_comfort': 0.0, 'temperatures': [20.18931808585136, 20.29405827053844, 20.20381916677713, 20.28394028484239, 20.71458508011669]}\n",
      "Reward:  -113725.17325724289 {'timestep': 32064, 'time_elapsed': 28857600, 'year': 1991, 'month': 12, 'day': 1, 'hour': 0, 'action': [20, 25], 'reward': -0.10562421590482962, 'reward_energy': -0.43777001948665334, 'reward_comfort': -0.06871912661796031, 'total_energy': 4377.700194866533, 'abs_comfort': 0.06871912661796031, 'temperatures': [19.97695926992562, 19.98738020179612, 19.97985790323261, 19.98708349842769, 20.33430431539913]}\n",
      "Reward:  -119382.97102101895 {'timestep': 35040, 'time_elapsed': 31536000, 'year': 1992, 'month': 1, 'day': 1, 'hour': 0, 'action': [20, 25], 'reward': -2.8486921929102653, 'reward_energy': -2.292872400871031, 'reward_comfort': -2.9104499475812915, 'total_energy': 22928.72400871031, 'abs_comfort': 2.9104499475812915, 'temperatures': [19.49726392106858, 19.16030849177053, 19.48252021938542, 19.13283200277385, 19.81662541742033]}\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    obs, info = env.reset()\n",
    "    rewards = []\n",
    "    observations = []\n",
    "    terminated = False\n",
    "    current_month = 0\n",
    "    while not terminated:\n",
    "        a = env.action_space.sample()\n",
    "        obs, reward, terminated, truncated, info = env.step(a)\n",
    "#         print('Obs: ', obs)\n",
    "        rewards.append(reward)\n",
    "        observations.append(obs)\n",
    "        if info['month'] != current_month:  # display results every month\n",
    "            current_month = info['month']\n",
    "            print('Reward: ', sum(rewards), info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward:  -3.4070482597321616 Cumulative reward:  -119382.97102101895\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'Mean reward: ',\n",
    "    np.mean(rewards),\n",
    "    'Cumulative reward: ',\n",
    "    sum(rewards))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-05-17 06:02:37,810] EPLUS_ENV_demo-v1_MainThread_ROOT INFO:EnergyPlus simulation closed successfully. \n"
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OKAY\n",
      "Lists length don't match\n"
     ]
    }
   ],
   "source": [
    "test_str = [\"asd\"]\n",
    "test_list = [\"asdkj\", \"askdj\"]\n",
    "\n",
    "if (type(test_str) == type(test_list)):\n",
    "    print('OKAY')\n",
    "    if (type(test_str) == list and len(test_str) != len(test_list)):\n",
    "        print(\"Lists length don't match\")\n",
    "else: \n",
    "    print('not same type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
